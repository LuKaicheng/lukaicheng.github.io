<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Lucifer"><meta name="description" content="引言在上一篇HDFS学习总结之基本原理的最后提到，由于名称节点容易成为整个HDFS系统的单点故障，这极大限制了hadoop系统在生产环境的使用场景。在hadoop1.x中，虽然有所谓的SecondaryNameNode，然而对于它的定位仅仅只是NameNode的辅助者，严格来讲"><meta name="keywords" content="Hadoop,HDFS"><title>HDFS学习总结之高可用 · Way to architect</title><link rel="icon" href="/favicon.ico"><link rel="canonical" href="https://lukaicheng.github.io/2017/08/09/HDFS-HA-Notes/"><link rel="alternate" href="/atom.xml" title="Way to architect"><link rel="stylesheet" href="/fonts/iconfont/iconfont.css"><link rel="stylesheet" href="/css/style.css"><script type="text/javascript">var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?Your baidu Analytics ID";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'Your Google Analytics ID', 'auto');
ga('send', 'pageview');</script></head><body><div id="main"><header><a href="/." class="logo">Way to architect</a><ul class="nav"><li class="nav-link"><a href="/" target="_self">Home</a></li><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/tags/" target="_self">Tags</a></li></ul></header><section id="container"><article class="post"><h1 class="post-title">HDFS学习总结之高可用</h1><span class="post-time">Aug 9, 2017</span><div id="sidebar" class="post-sidebar"><h3 class="heading">Contents</h3><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#引言"><span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#元数据"><span class="toc-text">元数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#EditLog"><span class="toc-text">EditLog</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FsImage"><span class="toc-text">FsImage</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Secondary-NameNode"><span class="toc-text">Secondary NameNode</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#高可用架构"><span class="toc-text">高可用架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#共享存储"><span class="toc-text">共享存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#提交EditLog"><span class="toc-text">提交EditLog</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#同步EditLog"><span class="toc-text">同步EditLog</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#主备切换"><span class="toc-text">主备切换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#隔离"><span class="toc-text">隔离</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text">参考</span></a></li></ol></div><div class="post-content"><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在上一篇<a href="https://lukaicheng.github.io/2017/08/02/HDFS-Basic-Notes/">HDFS学习总结之基本原理</a>的最后提到，由于名称节点容易成为整个HDFS系统的单点故障，这极大限制了hadoop系统在生产环境的使用场景。在hadoop1.x中，虽然有所谓的<strong>Secondary NameNode</strong>，然而对于它的定位仅仅只是<strong>NameNode</strong>的辅助者，严格来讲连冷备都算不上。幸运的是，在hadoop2.x版本里，经过多次迭代和发展，对于HDFS来说终于有了一套较为成熟可靠的高可用方案：<strong>QJM</strong>(<em>Quorum Journal Manager</em>)。本文将以此为中心，梳理和总结HDFS高可用的相关知识。</p>
<a id="more"></a>
<h2 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h2><p>众所周知，名称节点管理了整个HDFS系统的元数据信息，在运行期间，元数据信息在内存中不断更新，为了防止数据丢失，这些数据操作记录会被到<strong>EditLog</strong>文件中，辅助节点(<em>Secondary NameNode</em>)会帮助名称节点定时将产生的<strong>EditLog</strong>文件合并到<strong>FsImage</strong>文件，其中元数据存储目录结构如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/LuKaicheng/lukaicheng.github.io/hexo/source/images/hdfs/HDFS_NN_Metadata.png" alt="HDFS名称节点元数据存储目录结构"></p>
<h3 id="EditLog"><a href="#EditLog" class="headerlink" title="EditLog"></a>EditLog</h3><p>当客户端提交创建文件或移动文件这种的写操作时，名称节点会首先把这些操作记录在<strong>EditLog</strong>文件中，然后再更新内存中的文件系统镜像。记录在<strong>EditLog</strong>之中的每一个操作称为一个事务，会有一个整型的事务编号，整个<strong>EditLog</strong>会被切割为很多段，每一段称为一个<strong>Segment</strong>。具体表现出来就是目录下存在多个edits前缀的文件，其中文件名形式为<code>edits_inprogress_${start_txid}</code>表示是当前正在写入的EditLog Segment，<code>${start_txid}</code>表示这个Segment的起始事务id，如果是已经写入完成的EditLog Segment，那么会处于finalized状态，其文件名形式<code>edits_${start_txid}_${end_txid}</code>，<code>${start_txid}</code>表示这个segment的起始事务id，<code>${end_txid}</code>表示这个segment的结束事务id。</p>
<p>通过执行命令(<strong><em>hdfs oev</em></strong>)，我将一个edits文件以xml保存，这样可以具体看一下内部的数据样例。可以明显看到，里面每一个<strong>Record</strong>表示一次事务操作，每个事务操作会包含<strong>OPCODE</strong>和<strong>TXID</strong>： </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">EDITS</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">EDITS_VERSION</span>&gt;</span>-60<span class="tag">&lt;/<span class="name">EDITS_VERSION</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_START_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>876470<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ADD<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>876471<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">INODEID</span>&gt;</span>156307<span class="tag">&lt;/<span class="name">INODEID</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/hbase/WALs/hadoop08,60020,1499320794483/hadoop08%2C60020%2C1499320794483.default.1501664647096<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">REPLICATION</span>&gt;</span>3<span class="tag">&lt;/<span class="name">REPLICATION</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">MTIME</span>&gt;</span>1501664647540<span class="tag">&lt;/<span class="name">MTIME</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">ATIME</span>&gt;</span>1501664647540<span class="tag">&lt;/<span class="name">ATIME</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">BLOCKSIZE</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">BLOCKSIZE</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">CLIENT_NAME</span>&gt;</span>DFSClient_NONMAPREDUCE_1675402001_1<span class="tag">&lt;/<span class="name">CLIENT_NAME</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">CLIENT_MACHINE</span>&gt;</span>172.23.25.141<span class="tag">&lt;/<span class="name">CLIENT_MACHINE</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">OVERWRITE</span>&gt;</span>false<span class="tag">&lt;/<span class="name">OVERWRITE</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">PERMISSION_STATUS</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">USERNAME</span>&gt;</span>ceshi<span class="tag">&lt;/<span class="name">USERNAME</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">GROUPNAME</span>&gt;</span>supergroup<span class="tag">&lt;/<span class="name">GROUPNAME</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">MODE</span>&gt;</span>420<span class="tag">&lt;/<span class="name">MODE</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">PERMISSION_STATUS</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">RPC_CLIENTID</span>&gt;</span>a7425087-ddc0-40af-8974-f62a4ae6aadf<span class="tag">&lt;/<span class="name">RPC_CLIENTID</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>115918<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ALLOCATE_BLOCK_ID<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>876472<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073823335<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">EDITS</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="FsImage"><a href="#FsImage" class="headerlink" title="FsImage"></a>FsImage</h3><p><strong>FsImage</strong>记录了自最后一次检查点之前HDFS文件系统所有目录和文件的序列化信息，辅助节点会周期性地从名称节点处获取<strong>EditLog</strong>和<strong>FsImage</strong>进行合并，为名称节点生成新的<strong>FsImage</strong>文件，来替代旧文件。从目录结构图可以看到<strong>FsImage</strong>文件名称形式是<code>fsimage_${end_txid}</code>，其中<code>${end_txid}</code>表示结束事务id。在名称节点启动时，会首先将<strong>FsImage</strong>文件加载到内存中形成内存文件系统镜像，然后再把位于该<strong>FsImage</strong>文件之后(<em>edits文件名中的起始事务id大于fsimage文件名中的结束事务id</em>)的<strong>EditLog</strong>回放到该镜像，完成数据恢复。</p>
<p>同样的，通过执行命令(<strong><em>hdfs oiv</em></strong>)，我将一个fsimage文件以XML形式保存，下面是省略了大部分内容之后的样例：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">fsimage</span>&gt;</span> </div><div class="line">  <span class="tag">&lt;<span class="name">inode</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>17294<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>data.txt<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1492744099454<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">atime</span>&gt;</span>1495524378479<span class="tag">&lt;/<span class="name">atime</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">perferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">perferredBlockSize</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">permission</span>&gt;</span>ceshi:supergroup:rwxr-xr-x<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">blocks</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">block</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>1073742303<span class="tag">&lt;/<span class="name">id</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1479<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>437<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span></div><div class="line">      <span class="tag">&lt;/<span class="name">block</span>&gt;</span> </div><div class="line">    <span class="tag">&lt;/<span class="name">blocks</span>&gt;</span> </div><div class="line">  <span class="tag">&lt;/<span class="name">inode</span>&gt;</span> </div><div class="line"><span class="tag">&lt;/<span class="name">fsimage</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h3><p>从前文知道，名称节点通过将元数据信息保存在<strong>EditLog</strong>和<strong>FsImage</strong>中得以持久化，然而由于生产环境中名称节点很少重启，那么如果没有机制来合并<strong>EditLog</strong>和<strong>FsImage</strong>，那么会导致下一次重启名称节点花费更多时间，而且大量的<strong>EditLog</strong>也不好管理。为了解决这个问题且不加重名称节点的负担，因此引入了所谓的<strong>Secondary NameNode</strong>这个辅助节点。整体处理流程如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/LuKaicheng/lukaicheng.github.io/hexo/source/images/hdfs/HDFS_Checkpoint.png" alt="HDFS辅助节点备份合并过程"></p>
<p>整个过程也被称为一个<strong>Checkpoint</strong>，大致描述：</p>
<ol>
<li>辅助节点向名称节点请求合并edits文件，名称节点会创建新的edits.new</li>
<li>辅助节点向名称节点请求fsimage文件和edits文件</li>
<li>辅助节点把edits文件和fsimage文件合并，生成新的fsimage文件</li>
<li>名称节点获取新的fsimage文件，并将edits.new替换原来的edits文件</li>
</ol>
<h2 id="高可用架构"><a href="#高可用架构" class="headerlink" title="高可用架构"></a>高可用架构</h2><p>目前hadoop2.x中提出的基于QJM的HDFS高可用整体架构示意如下：</p>
<p><img src="https://raw.githubusercontent.com/LuKaicheng/lukaicheng.github.io/hexo/source/images/hdfs/HDFS_QJM_HA.png" alt="HDFS QJM高可用整体架构"></p>
<p>主要分成以下几个部分：</p>
<ul>
<li>名称节点：有Active和Standby之分，前者为主名称节点，对外提供读写服务，后者作为备用。</li>
<li>主备切换：通过ZKFailoverController检测名称节点的健康状态，在主名称节点故障时，借助ZooKeeper的主备选举支持，来实现自动的主备切换。</li>
<li>共享存储：整个高可用架构的核心部分，通过共享存储实现元数据同步，基于paxos算法。</li>
<li>数据节点：需要同时向主名称节点和备用名称节点上报数据块位置。</li>
</ul>
<h2 id="共享存储"><a href="#共享存储" class="headerlink" title="共享存储"></a>共享存储</h2><p>实现HDFS高可用最为关键的部分就是共享存储系统，前文提到名称节点的元数据会持久化到<strong>FsImage</strong>和<strong>EditLog</strong>这两个文件，而基于QJM的共享存储系统主要用于保存<strong>EditLog</strong>(<em>并不保存FsImage</em>)。其基本思想来自于Paxos算法，采用多个称为<strong>JournalNode</strong>节点组成的集群来存储<strong>EditLog</strong>，主名称节点首先把<strong>EditLog</strong>提交到<strong>JournalNode</strong>集群，然后备用名称节点再从<strong>JournalNode</strong>集群定时同步<strong>EditLog</strong>。</p>
<p><img src="https://raw.githubusercontent.com/LuKaicheng/lukaicheng.github.io/hexo/source/images/hdfs/HDFS_JournalNode_Set.png" alt="共享存储整体架构"></p>
<p>上图是共享存储系统的一个整体视图，下面会针对这两个过程再展开描述。</p>
<h3 id="提交EditLog"><a href="#提交EditLog" class="headerlink" title="提交EditLog"></a>提交EditLog</h3><p>当主名称节点需要提交<strong>EditLog</strong>时，它不仅需要写入本地磁盘目录，同时还要写入到<strong>JournalNode</strong>集群，后者会通过RPC方式并行的请求每个<strong>JournalNode</strong>进行写入，如果对大多数<strong>JournalNode</strong>都写入成功的话，那么就认为提交<strong>EditLog</strong>成功，否则会视为本次提交失败，这个失败会导致目前的主名称节点停止服务退出进程，留待处于备用状态的名称节点接管进行数据恢复。</p>
<p><img src="https://raw.githubusercontent.com/LuKaicheng/lukaicheng.github.io/hexo/source/images/hdfs/HDFS_JournalNode_Detail.png" alt="JournalNode写入流程"></p>
<h3 id="同步EditLog"><a href="#同步EditLog" class="headerlink" title="同步EditLog"></a>同步EditLog</h3><p>处于备用状态的名称节点，会启动一个<code>EditLogTailer</code>线程，这个线程的作用就是定期调用<code>doTailEdits</code>方法从<strong>JournalNode</strong>集群上同步<strong>EditLog</strong>，然后将它回放到内存的文件系统镜像上(<em>不会写入本地磁盘</em>)。这里需要注意的是，获取过来的<strong>EditLog</strong>都是处于finalized状态的<strong>Segment</strong>。另外，由于采用的是定时同步方式，所以备用名称节点内存中的文件系统镜像有很大可能性会落后于当前的主名称节点，因此当发生主备切换时，需要先把落后的<strong>EditLog</strong>补上来。</p>
<p><img src="https://raw.githubusercontent.com/LuKaicheng/lukaicheng.github.io/hexo/source/images/hdfs/HDFS_JournalNode_Recovery.png" alt="NameNode补齐EditLog"></p>
<p>上图就描述了当备用名称节点转换成主名称节点之后，进行数据恢复的大致流程：首先为了标识本次主名称节点的生命周期需要确定一个纪元(Epoch)，接着选择出数据恢复的EditLog Segment的id，据此选定同步的基准数据源，让<strong>JournalNode</strong>集群上的各个节点的<strong>EditLog</strong>恢复一致，最终当大多数已经处于一致状态，主名称节点就会从集群上补齐落后的<strong>EditLog</strong>数据。</p>
<h2 id="主备切换"><a href="#主备切换" class="headerlink" title="主备切换"></a>主备切换</h2><p>共享存储可以说解决了主备节点之间的数据同步问题，那么剩下的就是实现自动的故障转移，即主备切换，这个工作主要由<code>ZKFailoverController</code>进程来实现。<code>ZKFailoverController</code>会在名称节点上以独立进程启动，启动的时候会创建<code>HealthMonitor</code>和<code>ActiveStandbyElector</code>，分别负责名称节点的健康检测和自动的主备选举。这其中大致的过程如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/LuKaicheng/lukaicheng.github.io/hexo/source/images/hdfs/HDFS_NN_Switch.png" alt="主备切换"></p>
<ol>
<li><code>HealthMonitor</code>启动之后会定时对名称节点的健康状态进行检测。</li>
<li><code>HealthMonitor</code>如果发现名称节点的健康状态发生变化，将会回调通知<code>ZKFailoverController</code>进行处理。</li>
<li><code>ZKFailoverController</code>如果判定需要进行主备切换，那么会让<code>ActiveStandbyElector</code>进行自动的主备选举。</li>
<li><code>ActiveStandbyElector</code>与Zookeeper进行交互完成自动的主备选举。</li>
<li><code>ActiveStandbyElector</code>将会通过回调将选举结果通知<code>ZKFailoverController</code>，来决定当前名称节点成为主节点或者备节点。</li>
<li>最终<code>ZKFailoverController</code>会调用名称节点的RPC接口将其切换成正确的状态。</li>
</ol>
<p>其中步骤4中主备选举的机制主要是依赖于Zookeeper的写一致性和临时节点机制：如果<code>HealthMonitor</code>检测其对应的名称节点正常，那么<code>ActiveStandbyElector</code>会发起主备选举，尝试在Zookeeper创建一个临时节点(<em>/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock</em>)，Zookeeper保证只有一个能成功，其余则会失败。成功创建的对应的名称节点会成为主节点，失败的则是备用节点，但是不管成功还是失败，<code>ActiveStandbyElector</code>都会对这个临时节点进行监听。一旦主名称节点的<code>HealthMonitor</code>检测到其状态异常，<code>ZKFailoverController</code>会主动删除该临时节点，这时候监听了此节点的<code>ActiveStandbyElector</code>就能收到通知，重新触发主备选举。</p>
<h2 id="隔离"><a href="#隔离" class="headerlink" title="隔离"></a>隔离</h2><p>在这个高可用的架构设计中，还有一个比较值得注意的点是任何时间，只允许一个名称节点处于活动状态。因此为了避免可能发生的脑裂(<em>split-brain</em>)，有必要进行隔离(<em>fencing</em>)。</p>
<p>由前文可知在主备选举的时候会在Zookeeper创建一个临时节点，除此之外还会创建另外一个持久化节点(<em>/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb</em>)，如果主名称节点是正常关闭，那么会同时删除该节点，如果由于异常原因关闭，那么这个持久化节点还会存在，这时候新的选举出来的主名称节点会尝试对旧主节点进行状态转换，如果失败会执行隔离措施(<em>sshfence或者shellfence</em>)，只有隔离成功，新主才能开始对外提供服务。</p>
<p>另外就是在新的主名称节点进行数据恢复时，会产生新的纪元(Epoch)，<strong>JournalNode</strong>集群会保存新的纪元，以此为依据来判定应该允许还是拒绝接受到的写操作请求。由于新纪元肯定大于老纪元，所以原先的主名称节点如果尝试写日志操作的话，将会被拒绝。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/index.html" target="_blank" rel="external">Hadoop NameNode 高可用 (High Availability) 实现解析</a></p>
</div></article><div class="tags"><a href="/tags/Hadoop/">Hadoop</a><a href="/tags/HDFS/">HDFS</a></div><div class="paginator"><a href="/2017/08/02/HDFS-Basic-Notes/" class="next"><span>Next</span><i class="iconfont icon-right"></i></a></div><section id="comments"><div id="disqus_thread"></div></section><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://lukaicheng.github.io/2017/08/09/HDFS-HA-Notes/';
    this.page.identifier = '2017/08/09/HDFS-HA-Notes/';
    this.page.title = 'HDFS学习总结之高可用';
};
(function() {
var d = document, s = d.createElement('script');

s.src = '//Your disqus ID.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();</script></section><footer><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2017<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Lucifer</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script></body></html>